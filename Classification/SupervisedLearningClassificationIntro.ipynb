{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning: classification\n",
    "\n",
    "In this exercise we will work with two types of classification models. To do so, we will make use of functions from the SKLEARN library. This library contains a lot of machine learning algorithms that are used in practise, so it is very valuable to familiarize yourself with the SKLEARN library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/Daphne310/TrainingCases/master/iris-data-training.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation \n",
    "\n",
    "We just loaded the iris dataset. It contains data of three types of irisses. The features are measures of the lenght and width of the sepal and petal. Let's first split the data in features and targets. The iris dataset is a well-defined set for educational purposes, but in practise you will have to define the features and targets before this step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris[['sepal_length_cm', 'sepal_width_cm',\n",
    "                             'petal_length_cm', 'petal_width_cm']].values\n",
    "target = iris['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of the data, we will print the first example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The features of the first example are: ', data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The label of the first example is: ', target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to do is to create a trainset and a testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, \n",
    "                                                  test_size=1/3, random_state=0)\n",
    "\n",
    "print('The number of measurements are: ', data.shape[0])\n",
    "print('The number of training measurements are: ',X_train.shape[0])\n",
    "print('The number of test measurements are: ',X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct the classifier, we follow a few simple steps: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: Choose the type of classifier \n",
    "DTalgorithm = tree.DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#STEP 2: Fit the model to the train data\n",
    "DTalgorithm = DTalgorithm.fit(X_train, y_train)\n",
    "\n",
    "#STEP 3: Predict the labels of the test data \n",
    "Pred_DT = DTalgorithm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You just made a predictive algorithm!\n",
    "\n",
    "The variable 'Pred_DT' holds the predictions made by the algorithm. Now let's take a look at your performance using classification accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_CA = accuracy_score(y_test, Pred_DT) \n",
    "\n",
    "print('The Decision Tree Classifier reached a Classification Accuracy of: ', DT_CA)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Did you get a good score? \n",
    "\n",
    "We are not done yet, though. We might be able to reach a better performance by tuning the parameters. The Decision Tree Classifier has lots of parameters, but one of them is: \n",
    " \n",
    "- Minimal Split: The minimum number of samples required to split an internal node  \n",
    "- Maximal depth (how deep the tree should go). \n",
    "- Maximum number of features \n",
    "\n",
    "Go back to the code in STEP 1 and play around with the parameters. \n",
    "\n",
    "For example: DTalgorithm = tree.DecisionTreeClassifier(min_samples_split = 10, max_depth=7, max_features=3) \n",
    "\n",
    "Check the impact this has on the classification accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct the classifier, we follow a few simple steps: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: Choose the type of classifier \n",
    "KNNalgorithm = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "#STEP 2: Fit the model to the train data\n",
    "KNNalgorithm = KNNalgorithm.fit(X_train, y_train)\n",
    "\n",
    "#STEP 3: Predict the labels of the test data \n",
    "Pred_KNN = KNNalgorithm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You did it again!\n",
    "\n",
    "The variable 'Pred_KNN' holds the predictions made by the algorithm. Now let's take a look at your performance using classification accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_CA = accuracy_score(y_test, Pred_KNN) \n",
    "\n",
    "print('The K-Nearest Neighbors Classifier reached a Classification Accuracy of: ', KNN_CA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Did you get a good score? \n",
    "\n",
    "By know you probably know the drill. Tuning the parameters might help to reach a better performance. For K-Nearest Neighbors the most important parameter is the number of neighbors taken into account. The code now says 'n_neighbors = 3'. Play around with the number to see if the model can be improved. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "What model eventually reached the highest classification accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Decision Tree Classifier reached a Classification Accuracy of: ', DT_CA)\n",
    "print('The K-Nearest Neighbors Classifier reached a Classification Accuracy of: ', KNN_CA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "Is this test enough to determine which model has the best fit?\n",
    "Tip: change the values of the random_state in train/test split and in the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
